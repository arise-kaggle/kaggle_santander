{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488701b1-2d56-42d9-a3e8-12d2701531e0",
   "metadata": {},
   "source": [
    "# scripts/convert_to_feather.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487cc748-a835-4e5e-8dbb-bced2d8e186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293eadd2-45eb-4d22-91e5-e6cc8d7dfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\n",
    "    'train_ver2',\n",
    "    'test_ver2',\n",
    "]\n",
    "\n",
    "extension = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2f7c01-ee9c-459d-a4cd-7d3fed206f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== train_ver2 の作成開始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (5,8,11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== train_ver2 の作成完了\n",
      "=== test_ver2 の作成開始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== test_ver2 の作成完了\n"
     ]
    }
   ],
   "source": [
    "for t in target:\n",
    "    \n",
    "    print(f'=== {t} の作成開始')\n",
    "    \n",
    "    df = pd.read_csv('../data/input/' + t + '.' + extension, encoding=\"utf-8\")\n",
    "    \n",
    "    ## データクレンジングしてからfeather化 ##\n",
    "    # 不正な値があるカラム 'age', 'antiguedad', 'indrel_1mes', 'conyuemp'\n",
    "    \n",
    "    # 数値型変数の特異値と欠損値を -99に代替し、整数型に変換します。\n",
    "    df['age'].replace(' NA', -99, inplace=True)\n",
    "    df['age'] = df['age'].astype(np.int8)\n",
    "    df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "    df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "    df['renta'].replace('         NA', -99, inplace=True)\n",
    "    df['renta'].fillna(-99, inplace=True)\n",
    "    df['renta'] = df['renta'].astype(float).astype(np.int8\n",
    "    df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "    df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "    df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "    df['conyuemp'].fillna('N', inplace=True) # Nが多いのでNで穴埋め\n",
    "    \n",
    "    df.to_feather('../data/input/' + t + '.feather')\n",
    "    \n",
    "    print(f'=== {t} の作成完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670a4d3-f5bc-4cf4-ada6-122b9be5f5e1",
   "metadata": {},
   "source": [
    "# features/create.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef3ff2b-22f1-4f0c-a5f1-11aaaa54d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import sys\n",
    "\n",
    "sys.path.append('../features/')\n",
    "from base import Feature, get_arguments, generate_features\n",
    "\n",
    "Feature.dir = 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6583aec-cced-4aa5-8dec-f9f6c42f4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付を数字に変換する関数です。 2015-01-28は 1, 2016-06-28は 18に変換します。\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b717b1e-40e0-4a57-a4eb-70ac35b822b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 48)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'date_to_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8078/2647192517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# コード 2-12と類似したコードの流れです\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# 日付を数字に変換し int_dateに保存します。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fecha_dato'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# generate_features(globals(), args.force)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'date_to_int' is not defined"
     ]
    }
   ],
   "source": [
    "# args = get_arguments()\n",
    "\n",
    "'''\n",
    "    読み込み・準備\n",
    "\n",
    "'''\n",
    "\n",
    "train = pd.read_feather('../data/input/train_ver2.feather')\n",
    "\n",
    "test = pd.read_feather('../data/input/test_ver2.feather')\n",
    "\n",
    "# 製品の変数を別途に保存しておきます。\n",
    "prods = train.columns[24:].tolist()\n",
    "\n",
    "# 24個の製品を1つも保有していない顧客のデータを除去します。\n",
    "no_product = train[prods].sum(axis=1) == 0\n",
    "train= train[~no_product]\n",
    "## あとで消す\n",
    "# メモリに乗らないのでサンプリング\n",
    "train = train.sample(1000000)\n",
    "print(train.shape)\n",
    "\n",
    "# 製品変数の欠損値をあらかじめ0に代替しておきます。\n",
    "train[prods] = train[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# 訓練データとテストデータを統合します。テストデータにない製品変数は0で埋めます。\n",
    "for col in train.columns[24:]:\n",
    "    test[col] = 0\n",
    "\n",
    "'''\n",
    "    trainとtestをunionしてデータフレームを作成\n",
    "\n",
    "'''    \n",
    "    \n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "'''\n",
    "    データ加工\n",
    "\n",
    "'''\n",
    "\n",
    "# カテゴリ変数を .factorize() 関数に通して label encodingします。\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "\n",
    "# (特徴量エンジニアリング) 2つの日付変数から年度と月の情報を抽出します。\n",
    "df['fecha_alta'].fillna(0.0, inplace=True)\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "df = df.drop(['fecha_alta'], axis =1)\n",
    "\n",
    "df['ult_fec_cli_1t'].fillna(0.0, inplace=True)\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "df['ult_fec_cli_1t'] = df['ult_fec_cli_1t'].astype(object)\n",
    "df = df.drop(['ult_fec_cli_1t'], axis =1)\n",
    "\n",
    "# それ以外の変数の欠損値をすべて -99に代替します。\n",
    "df.fillna(-99, inplace=True)\n",
    "\n",
    "# (特徴量エンジニアリング) lag-1 データを生成します。\n",
    "# コード 2-12と類似したコードの流れです\n",
    "# 日付を数字に変換し int_dateに保存します。\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "# generate_features(globals(), args.force)\n",
    "\n",
    "'''\n",
    "    保存\n",
    "\n",
    "'''\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_feather('../data/input/' + 'df' + '.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22756b-d4df-4c42-8409-83bcdcfb025e",
   "metadata": {},
   "source": [
    "# run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4309c50d-e168-40fc-beaa-f7071467a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import argparse\n",
    "import json\n",
    "import gc\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c9a208-90d6-4493-851f-2154d43f6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    # AP@7なので、最大7個まで使用します。\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # 点数を付与する条件は次のとおり :\n",
    "        # 予測値が正答に存在し (‘p in actual’)\n",
    "        # 予測値に重複がなければ (‘p not in predicted[:i]’) \n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    # 正答値が空白である場合、ともかく 0.0点を返します。\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    # 正答の個数(len(actual))として average precisionを求めます。\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    # list of listである正答値(actual)と予測値(predicted)から顧客別 Average Precisionを求め, np.mean()を通して平均を計算します。\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345e8f4a-333b-4e09-a8d9-602152e896a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', default='../configs/default.json')\n",
    "# options = parser.parse_args()\n",
    "options = parser.parse_args([])\n",
    "config = json.load(open(options.config))\n",
    "\n",
    "prods = config['target']\n",
    "features = config['features']\n",
    "params = config['model_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61c1e49-8173-444d-99e3-faecb4e9a1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather('../data/input/' + 'df' + '.feather')\n",
    "\n",
    "# データをコピーし, int_date 日付に1を加え lagを生成します。変数名に _prevを追加します。\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1\n",
    "\n",
    "# 原本データと lag データを ncodperと int_date を基準として合わせます。lag データの int_dateは 1 だけ押されているため、前の月の製品情報が挿入されます。\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# メモリの効率化のために、不必要な変数をメモリから除去します。\n",
    "del df, df_lag\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bec174-d968-4729-b8b0-610770a0999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前の月の製品情報が存在しない場合に備えて、0に代替します。\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "df_trn.fillna(-99, inplace=True)\n",
    "\n",
    "# lag-1 変数を追加します。\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba082f3-8586-4948-a398-e643a0e27d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Baseline モデル以後、多様な特徴量エンジニアリングをここに追加します。\n",
    "###\n",
    "\n",
    "## モデル学習\n",
    "# 学習のため、データを訓練、検証用に分離します。\n",
    "# 学習には 2016-01-28 ~ 2016-04-28 のデータだけを使用し、検証には 2016-05-28 のデータを使用します。\n",
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f87502-852c-4cd0-b6b4-87c0b6007186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データから新規購買件数だけを抽出します。\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "# 訓練、検証データに分離します。\n",
    "vld_date = '2016-05-28'\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c78751c-e8c7-4ee7-b48f-001cbb757f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lightgbm.callback import _format_eval_result\n",
    "\n",
    "\n",
    "def log_best(model, metric):\n",
    "    logging.debug(model.best_iteration)\n",
    "    logging.debug(model.best_score['valid_0'][metric])\n",
    "\n",
    "\n",
    "def log_evaluation(logger, period=1, show_stdv=True, level=logging.DEBUG):\n",
    "    def _callback(env):\n",
    "        if period > 0 and env.evaluation_result_list \\\n",
    "                and (env.iteration + 1) % period == 0:\n",
    "            result = '\\t'.join([\n",
    "                _format_eval_result(x, show_stdv)\n",
    "                for x in env.evaluation_result_list\n",
    "            ])\n",
    "            logger.log(level, '[{}]\\t{}'.format(env.iteration + 1, result))\n",
    "    _callback.order = 10\n",
    "    return _callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60756e4f-ecc2-4466-8ed5-cab1f5ab8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "# from logs.logger import log_evaluation\n",
    "\n",
    "\n",
    "def train_and_predict(X_train, X_valid, y_train, y_valid, X_test, params):\n",
    "\n",
    "    # データセットを生成する\n",
    "    xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "    xgb_eval  = xgb.DMatrix(X_valid, y_valid)\n",
    "    \n",
    "    watch_list = [(xgb_train, 'train'), (xgb_eval, 'eval')]\n",
    "\n",
    "    logging.debug(params)\n",
    "\n",
    "    # ロガーの作成\n",
    "    logger = logging.getLogger('main')\n",
    "    callbacks = [log_evaluation(logger, period=30)]\n",
    "\n",
    "    \n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = xgb.train(\n",
    "        params, xgb_train,\n",
    "        # モデルの評価用データを渡す\n",
    "        evals=watch_list,\n",
    "        # 最大で 1000 ラウンドまで学習する\n",
    "        num_boost_round=10,\n",
    "        # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "        early_stopping_rounds=20,\n",
    "        # ログ\n",
    "        # callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    xgb_test = xgb.DMatrix(X_test)\n",
    "    \n",
    "    # テストデータを予測する\n",
    "    y_pred = model.predict(xgb_test, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    # pickle.dump(model, open(\"xgb.baseline.pkl\", \"wb\"))\n",
    "    # best_ntree_limit = model.best_ntree_limit\n",
    "\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2f6b41-f45e-41bf-9561-518d3361b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練、検証データを XGBoost 形態に変換します。\n",
    "X_trtrain = XY_trn[features].values\n",
    "Y_trtrain = XY_trn['y'].values\n",
    "\n",
    "X_trvalid = XY_vld[features].values\n",
    "Y_trvalid = XY_vld['y'].values\n",
    "\n",
    "# XGBoost モデルを訓練データで学習させます！\n",
    "# watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "# model = xgb.train(param, dtrn, num_boost_round=10, evals=watch_list, early_stopping_rounds=20)\n",
    "\n",
    "# # 学習したモデルを保存します。\n",
    "# import pickle\n",
    "# pickle.dump(model, open(\"xgb.baseline.pkl\", \"wb\"))\n",
    "# best_ntree_limit = model.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095e7b1b-c8c1-4253-a74c-1c0993406697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "# MAP@7 評価基準のための準備作業です。\n",
    "# 顧客識別番号を抽出します。\n",
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld['ncodpers'].values\n",
    "# 検証データから新規購買を求めます。\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]    \n",
    "add_vld = vld[[prod + '_add' for prod in prods]].values\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
    "\n",
    "# 顧客別新規購買正答値を add_vld_listに保存し、総 countを count_vldに保存します。\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "797c3c7a-7ac1-4b4b-8ed9-067ca1475edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:29] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:2.78372\teval-mlogloss:2.78954\n",
      "[1]\ttrain-mlogloss:2.60768\teval-mlogloss:2.61686\n",
      "[2]\ttrain-mlogloss:2.47880\teval-mlogloss:2.48968\n",
      "[3]\ttrain-mlogloss:2.37823\teval-mlogloss:2.39063\n",
      "[4]\ttrain-mlogloss:2.29472\teval-mlogloss:2.30823\n",
      "[5]\ttrain-mlogloss:2.22360\teval-mlogloss:2.23818\n",
      "[6]\ttrain-mlogloss:2.16244\teval-mlogloss:2.17824\n",
      "[7]\ttrain-mlogloss:2.10893\teval-mlogloss:2.12557\n",
      "[8]\ttrain-mlogloss:2.06174\teval-mlogloss:2.07920\n",
      "[9]\ttrain-mlogloss:2.02031\teval-mlogloss:2.03844\n",
      "[10]\ttrain-mlogloss:1.98285\teval-mlogloss:2.00163\n",
      "[11]\ttrain-mlogloss:1.94960\teval-mlogloss:1.96891\n",
      "[12]\ttrain-mlogloss:1.91934\teval-mlogloss:1.93921\n",
      "[13]\ttrain-mlogloss:1.89237\teval-mlogloss:1.91285\n",
      "[14]\ttrain-mlogloss:1.86746\teval-mlogloss:1.88854\n",
      "[15]\ttrain-mlogloss:1.84493\teval-mlogloss:1.86646\n",
      "[16]\ttrain-mlogloss:1.82425\teval-mlogloss:1.84621\n",
      "[17]\ttrain-mlogloss:1.80537\teval-mlogloss:1.82782\n",
      "[18]\ttrain-mlogloss:1.78827\teval-mlogloss:1.81118\n",
      "[19]\ttrain-mlogloss:1.77263\teval-mlogloss:1.79594\n",
      "[20]\ttrain-mlogloss:1.75804\teval-mlogloss:1.78174\n",
      "[21]\ttrain-mlogloss:1.74468\teval-mlogloss:1.76874\n",
      "[22]\ttrain-mlogloss:1.73271\teval-mlogloss:1.75707\n",
      "[23]\ttrain-mlogloss:1.72127\teval-mlogloss:1.74601\n",
      "[24]\ttrain-mlogloss:1.71070\teval-mlogloss:1.73583\n",
      "[25]\ttrain-mlogloss:1.70125\teval-mlogloss:1.72672\n",
      "[26]\ttrain-mlogloss:1.69227\teval-mlogloss:1.71808\n",
      "[27]\ttrain-mlogloss:1.68397\teval-mlogloss:1.71007\n",
      "[28]\ttrain-mlogloss:1.67614\teval-mlogloss:1.70265\n",
      "[29]\ttrain-mlogloss:1.66894\teval-mlogloss:1.69573\n",
      "[30]\ttrain-mlogloss:1.66228\teval-mlogloss:1.68936\n",
      "[31]\ttrain-mlogloss:1.65600\teval-mlogloss:1.68334\n",
      "[32]\ttrain-mlogloss:1.65028\teval-mlogloss:1.67791\n",
      "[33]\ttrain-mlogloss:1.64500\teval-mlogloss:1.67297\n",
      "[34]\ttrain-mlogloss:1.63995\teval-mlogloss:1.66820\n",
      "[35]\ttrain-mlogloss:1.63518\teval-mlogloss:1.66373\n",
      "[36]\ttrain-mlogloss:1.63076\teval-mlogloss:1.65959\n",
      "[37]\ttrain-mlogloss:1.62648\teval-mlogloss:1.65563\n",
      "[38]\ttrain-mlogloss:1.62256\teval-mlogloss:1.65198\n",
      "[39]\ttrain-mlogloss:1.61890\teval-mlogloss:1.64858\n",
      "[40]\ttrain-mlogloss:1.61544\teval-mlogloss:1.64542\n",
      "[41]\ttrain-mlogloss:1.61222\teval-mlogloss:1.64246\n",
      "[42]\ttrain-mlogloss:1.60916\teval-mlogloss:1.63963\n",
      "[43]\ttrain-mlogloss:1.60630\teval-mlogloss:1.63707\n",
      "[44]\ttrain-mlogloss:1.60353\teval-mlogloss:1.63456\n",
      "[45]\ttrain-mlogloss:1.60099\teval-mlogloss:1.63231\n",
      "[46]\ttrain-mlogloss:1.59860\teval-mlogloss:1.63018\n",
      "[47]\ttrain-mlogloss:1.59631\teval-mlogloss:1.62811\n",
      "[48]\ttrain-mlogloss:1.59415\teval-mlogloss:1.62619\n",
      "[49]\ttrain-mlogloss:1.59216\teval-mlogloss:1.62440\n",
      "[50]\ttrain-mlogloss:1.59022\teval-mlogloss:1.62271\n",
      "[51]\ttrain-mlogloss:1.58837\teval-mlogloss:1.62114\n",
      "[52]\ttrain-mlogloss:1.58659\teval-mlogloss:1.61963\n",
      "[53]\ttrain-mlogloss:1.58492\teval-mlogloss:1.61822\n",
      "[54]\ttrain-mlogloss:1.58331\teval-mlogloss:1.61685\n",
      "[55]\ttrain-mlogloss:1.58181\teval-mlogloss:1.61559\n",
      "[56]\ttrain-mlogloss:1.58037\teval-mlogloss:1.61438\n",
      "[57]\ttrain-mlogloss:1.57906\teval-mlogloss:1.61327\n",
      "[58]\ttrain-mlogloss:1.57780\teval-mlogloss:1.61223\n",
      "[59]\ttrain-mlogloss:1.57659\teval-mlogloss:1.61121\n",
      "[60]\ttrain-mlogloss:1.57540\teval-mlogloss:1.61026\n",
      "[61]\ttrain-mlogloss:1.57433\teval-mlogloss:1.60938\n",
      "[62]\ttrain-mlogloss:1.57331\teval-mlogloss:1.60854\n",
      "[63]\ttrain-mlogloss:1.57231\teval-mlogloss:1.60778\n",
      "[64]\ttrain-mlogloss:1.57136\teval-mlogloss:1.60701\n",
      "[65]\ttrain-mlogloss:1.57034\teval-mlogloss:1.60625\n",
      "[66]\ttrain-mlogloss:1.56948\teval-mlogloss:1.60556\n",
      "[67]\ttrain-mlogloss:1.56862\teval-mlogloss:1.60490\n",
      "[68]\ttrain-mlogloss:1.56777\teval-mlogloss:1.60426\n",
      "[69]\ttrain-mlogloss:1.56697\teval-mlogloss:1.60368\n",
      "[70]\ttrain-mlogloss:1.56618\teval-mlogloss:1.60311\n",
      "[71]\ttrain-mlogloss:1.56536\teval-mlogloss:1.60255\n",
      "[72]\ttrain-mlogloss:1.56451\teval-mlogloss:1.60198\n",
      "[73]\ttrain-mlogloss:1.56381\teval-mlogloss:1.60152\n",
      "[74]\ttrain-mlogloss:1.56312\teval-mlogloss:1.60107\n",
      "[75]\ttrain-mlogloss:1.56249\teval-mlogloss:1.60064\n",
      "[76]\ttrain-mlogloss:1.56188\teval-mlogloss:1.60023\n",
      "[77]\ttrain-mlogloss:1.56127\teval-mlogloss:1.59985\n",
      "[78]\ttrain-mlogloss:1.56070\teval-mlogloss:1.59944\n",
      "[79]\ttrain-mlogloss:1.56011\teval-mlogloss:1.59905\n",
      "[80]\ttrain-mlogloss:1.55951\teval-mlogloss:1.59870\n",
      "[81]\ttrain-mlogloss:1.55894\teval-mlogloss:1.59837\n",
      "[82]\ttrain-mlogloss:1.55841\teval-mlogloss:1.59808\n",
      "[83]\ttrain-mlogloss:1.55795\teval-mlogloss:1.59781\n",
      "[84]\ttrain-mlogloss:1.55747\teval-mlogloss:1.59751\n",
      "[85]\ttrain-mlogloss:1.55699\teval-mlogloss:1.59723\n",
      "[86]\ttrain-mlogloss:1.55654\teval-mlogloss:1.59699\n",
      "[87]\ttrain-mlogloss:1.55612\teval-mlogloss:1.59675\n",
      "[88]\ttrain-mlogloss:1.55573\teval-mlogloss:1.59652\n",
      "[89]\ttrain-mlogloss:1.55533\teval-mlogloss:1.59629\n",
      "[90]\ttrain-mlogloss:1.55487\teval-mlogloss:1.59607\n",
      "[91]\ttrain-mlogloss:1.55445\teval-mlogloss:1.59586\n",
      "[92]\ttrain-mlogloss:1.55408\teval-mlogloss:1.59567\n",
      "[93]\ttrain-mlogloss:1.55364\teval-mlogloss:1.59547\n",
      "[94]\ttrain-mlogloss:1.55326\teval-mlogloss:1.59528\n",
      "[95]\ttrain-mlogloss:1.55286\teval-mlogloss:1.59508\n",
      "[96]\ttrain-mlogloss:1.55248\teval-mlogloss:1.59492\n",
      "[97]\ttrain-mlogloss:1.55216\teval-mlogloss:1.59478\n",
      "[98]\ttrain-mlogloss:1.55184\teval-mlogloss:1.59463\n",
      "[99]\ttrain-mlogloss:1.55151\teval-mlogloss:1.59447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:94: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    }
   ],
   "source": [
    "# 検証データに対する予測値を求めます。\n",
    "X_trtest = vld[features].values\n",
    "# Y_vld = vld['y'].values\n",
    "# dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "# dvld = xgb.DMatrix(X_vld, feature_names=features)\n",
    "# preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
    "\n",
    "preds_vld, _ = train_and_predict(X_trtrain, X_trvalid, Y_trtrain, Y_trvalid, X_trtest, params)\n",
    "\n",
    "# 前の月に保有していた商品は新規購買が不可能なので、確率値からあらかじめ1を引いておきます。\n",
    "preds_vld = preds_vld - vld[[prod + '_prev' for prod in prods]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f70e95a6-5239-4b18-b243-f706c0256b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62713,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 916870,  635199, 1466134, ..., 1155913,  614097,  934569])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ncodpers_vld.shape)\n",
    "ncodpers_vld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39dd31e2-8205-4bde-99bd-ba26882d53f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62713, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.96035006e-04, 1.98312147e-04, 5.31811059e-01, ...,\n",
       "        5.69856819e-03, 6.76347222e-03, 3.75991575e-02],\n",
       "       [2.50592304e-04, 2.72935256e-04, 4.16709781e-01, ...,\n",
       "        2.40314789e-02, 2.84058321e-02, 7.63536245e-02],\n",
       "       [1.87220830e-05, 1.89389084e-05, 9.98408854e-01, ...,\n",
       "        7.07946674e-05, 6.38099737e-05, 1.54155219e-04],\n",
       "       ...,\n",
       "       [1.49319385e-04, 1.51647968e-04, 7.81946242e-01, ...,\n",
       "        1.22114792e-02, 1.21833170e-02, 1.30612224e-01],\n",
       "       [2.18878951e-04, 2.17627588e-04, 5.66130400e-01, ...,\n",
       "        3.62577266e-03, 6.01888215e-03, 2.09640358e-02],\n",
       "       [1.56922353e-04, 1.59369505e-04, 7.83915877e-01, ...,\n",
       "        2.65169702e-02, 2.80811060e-02, 9.32736844e-02]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preds_vld.shape)\n",
    "preds_vld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15039782-776c-405f-ad9c-5f731571c822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b40df506-de3e-48fc-af77-9fbc2472e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データの予測上位7個を抽出します。\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p,ip in y_prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dd1804c-c7b7-41cc-ba23-905a8b9b67d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9149139731794046\n"
     ]
    }
   ],
   "source": [
    "# 検証データから得ることのできる MAP@7 の最高点をあらかじめ求めておきます。(0.042663)\n",
    "print(mapk(add_vld_list, add_vld_list, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30eca003-4afa-4a3f-b67e-d9d883fab337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7808885724706436\n"
     ]
    }
   ],
   "source": [
    "# 検証データの MAP@7の点数を求めます。(0.036466)\n",
    "print(mapk(add_vld_list, result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c68a6089-7d1c-4640-88d1-a6a1bfa8e93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7824e46a-f09a-4a63-9eb4-21a1053ff202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>indrel_1mes</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_tjcr_fin_ult1_prev</th>\n",
       "      <th>ind_valo_fin_ult1_prev</th>\n",
       "      <th>ind_viv_fin_ult1_prev</th>\n",
       "      <th>ind_nomina_ult1_prev</th>\n",
       "      <th>ind_nom_pens_ult1_prev</th>\n",
       "      <th>ind_recibo_ult1_prev</th>\n",
       "      <th>fecha_alta_month_prev</th>\n",
       "      <th>fecha_alta_year_prev</th>\n",
       "      <th>ult_fec_cli_1t_month_prev</th>\n",
       "      <th>ult_fec_cli_1t_year_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000001</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000002</th>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1170545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha_dato  ncodpers  ind_empleado  pais_residencia  sexo  age  \\\n",
       "1000000  2016-06-28     15889             1                0     0   56   \n",
       "1000001  2016-06-28   1170544             0                0     1   36   \n",
       "1000002  2016-06-28   1170545             0                0     0   22   \n",
       "\n",
       "         ind_nuevo  antiguedad  indrel  indrel_1mes  ...  \\\n",
       "1000000        0.0           0     1.0            1  ...   \n",
       "1000001        0.0          34     1.0            1  ...   \n",
       "1000002        0.0          34     1.0            1  ...   \n",
       "\n",
       "         ind_tjcr_fin_ult1_prev  ind_valo_fin_ult1_prev  \\\n",
       "1000000                     0.0                     0.0   \n",
       "1000001                     0.0                     0.0   \n",
       "1000002                     0.0                     0.0   \n",
       "\n",
       "         ind_viv_fin_ult1_prev  ind_nomina_ult1_prev  ind_nom_pens_ult1_prev  \\\n",
       "1000000                    0.0                   0.0                     0.0   \n",
       "1000001                    0.0                   0.0                     0.0   \n",
       "1000002                    0.0                   0.0                     0.0   \n",
       "\n",
       "         ind_recibo_ult1_prev  fecha_alta_month_prev  fecha_alta_year_prev  \\\n",
       "1000000                   0.0                  -99.0                 -99.0   \n",
       "1000001                   0.0                  -99.0                 -99.0   \n",
       "1000002                   0.0                  -99.0                 -99.0   \n",
       "\n",
       "         ult_fec_cli_1t_month_prev  ult_fec_cli_1t_year_prev  \n",
       "1000000                      -99.0                     -99.0  \n",
       "1000001                      -99.0                     -99.0  \n",
       "1000002                      -99.0                     -99.0  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84f2478c-ea1c-497f-a6c0-715ae6e4c26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929615,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.ncodpers.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b2d3498-c96b-43c4-ab13-427f9bc14123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:49:38] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:2.78482\n",
      "[1]\ttrain-mlogloss:2.60897\n",
      "[2]\ttrain-mlogloss:2.48026\n",
      "[3]\ttrain-mlogloss:2.37990\n",
      "[4]\ttrain-mlogloss:2.29651\n",
      "[5]\ttrain-mlogloss:2.22555\n",
      "[6]\ttrain-mlogloss:2.16457\n",
      "[7]\ttrain-mlogloss:2.11114\n",
      "[8]\ttrain-mlogloss:2.06411\n",
      "[9]\ttrain-mlogloss:2.02269\n",
      "[10]\ttrain-mlogloss:1.98535\n",
      "[11]\ttrain-mlogloss:1.95211\n",
      "[12]\ttrain-mlogloss:1.92189\n",
      "[13]\ttrain-mlogloss:1.89494\n",
      "[14]\ttrain-mlogloss:1.87006\n",
      "[15]\ttrain-mlogloss:1.84761\n",
      "[16]\ttrain-mlogloss:1.82694\n",
      "[17]\ttrain-mlogloss:1.80808\n",
      "[18]\ttrain-mlogloss:1.79103\n",
      "[19]\ttrain-mlogloss:1.77539\n",
      "[20]\ttrain-mlogloss:1.76084\n",
      "[21]\ttrain-mlogloss:1.74749\n",
      "[22]\ttrain-mlogloss:1.73551\n",
      "[23]\ttrain-mlogloss:1.72411\n",
      "[24]\ttrain-mlogloss:1.71359\n",
      "[25]\ttrain-mlogloss:1.70415\n",
      "[26]\ttrain-mlogloss:1.69517\n",
      "[27]\ttrain-mlogloss:1.68687\n",
      "[28]\ttrain-mlogloss:1.67907\n",
      "[29]\ttrain-mlogloss:1.67189\n",
      "[30]\ttrain-mlogloss:1.66526\n",
      "[31]\ttrain-mlogloss:1.65903\n",
      "[32]\ttrain-mlogloss:1.65332\n",
      "[33]\ttrain-mlogloss:1.64808\n",
      "[34]\ttrain-mlogloss:1.64304\n",
      "[35]\ttrain-mlogloss:1.63833\n",
      "[36]\ttrain-mlogloss:1.63390\n",
      "[37]\ttrain-mlogloss:1.62966\n",
      "[38]\ttrain-mlogloss:1.62575\n",
      "[39]\ttrain-mlogloss:1.62214\n",
      "[40]\ttrain-mlogloss:1.61869\n",
      "[41]\ttrain-mlogloss:1.61549\n",
      "[42]\ttrain-mlogloss:1.61246\n",
      "[43]\ttrain-mlogloss:1.60967\n",
      "[44]\ttrain-mlogloss:1.60690\n",
      "[45]\ttrain-mlogloss:1.60441\n",
      "[46]\ttrain-mlogloss:1.60203\n",
      "[47]\ttrain-mlogloss:1.59972\n",
      "[48]\ttrain-mlogloss:1.59755\n",
      "[49]\ttrain-mlogloss:1.59556\n",
      "[50]\ttrain-mlogloss:1.59364\n",
      "[51]\ttrain-mlogloss:1.59177\n",
      "[52]\ttrain-mlogloss:1.59001\n",
      "[53]\ttrain-mlogloss:1.58839\n",
      "[54]\ttrain-mlogloss:1.58685\n",
      "[55]\ttrain-mlogloss:1.58537\n",
      "[56]\ttrain-mlogloss:1.58396\n",
      "[57]\ttrain-mlogloss:1.58262\n",
      "[58]\ttrain-mlogloss:1.58139\n",
      "[59]\ttrain-mlogloss:1.58019\n",
      "[60]\ttrain-mlogloss:1.57904\n",
      "[61]\ttrain-mlogloss:1.57797\n",
      "[62]\ttrain-mlogloss:1.57695\n",
      "[63]\ttrain-mlogloss:1.57595\n",
      "[64]\ttrain-mlogloss:1.57499\n",
      "[65]\ttrain-mlogloss:1.57404\n",
      "[66]\ttrain-mlogloss:1.57320\n",
      "[67]\ttrain-mlogloss:1.57235\n",
      "[68]\ttrain-mlogloss:1.57154\n",
      "[69]\ttrain-mlogloss:1.57078\n",
      "[70]\ttrain-mlogloss:1.57001\n",
      "[71]\ttrain-mlogloss:1.56926\n",
      "[72]\ttrain-mlogloss:1.56857\n",
      "[73]\ttrain-mlogloss:1.56797\n",
      "[74]\ttrain-mlogloss:1.56732\n",
      "[75]\ttrain-mlogloss:1.56673\n",
      "[76]\ttrain-mlogloss:1.56617\n",
      "[77]\ttrain-mlogloss:1.56561\n",
      "[78]\ttrain-mlogloss:1.56504\n",
      "[79]\ttrain-mlogloss:1.56451\n",
      "[80]\ttrain-mlogloss:1.56394\n",
      "[81]\ttrain-mlogloss:1.56336\n",
      "[82]\ttrain-mlogloss:1.56279\n",
      "[83]\ttrain-mlogloss:1.56229\n",
      "[84]\ttrain-mlogloss:1.56188\n",
      "[85]\ttrain-mlogloss:1.56143\n",
      "[86]\ttrain-mlogloss:1.56095\n",
      "[87]\ttrain-mlogloss:1.56051\n",
      "[88]\ttrain-mlogloss:1.56006\n",
      "[89]\ttrain-mlogloss:1.55965\n",
      "[90]\ttrain-mlogloss:1.55924\n",
      "[91]\ttrain-mlogloss:1.55891\n",
      "[92]\ttrain-mlogloss:1.55856\n",
      "[93]\ttrain-mlogloss:1.55819\n",
      "[94]\ttrain-mlogloss:1.55778\n",
      "[95]\ttrain-mlogloss:1.55743\n",
      "[96]\ttrain-mlogloss:1.55704\n",
      "[97]\ttrain-mlogloss:1.55674\n",
      "[98]\ttrain-mlogloss:1.55644\n",
      "[99]\ttrain-mlogloss:1.55612\n",
      "Feature importance:\n",
      "('antiguedad', 24367.0)\n",
      "('age', 22739.0)\n",
      "('renta', 21307.0)\n",
      "('nomprov', 14957.0)\n",
      "('fecha_alta_month', 12849.0)\n",
      "('canal_entrada', 12076.0)\n",
      "('fecha_alta_year', 11761.0)\n",
      "('segmento', 4052.0)\n",
      "('sexo', 4036.0)\n",
      "('tiprel_1mes', 2690.0)\n",
      "('ind_actividad_cliente', 2341.0)\n",
      "('indext', 1774.0)\n",
      "('pais_residencia', 814.0)\n",
      "('ind_nuevo', 678.0)\n",
      "('indfall', 424.0)\n",
      "('age_prev', 310.0)\n",
      "('ind_cno_fin_ult1_prev', 240.0)\n",
      "('ind_empleado', 238.0)\n",
      "('antiguedad_prev', 198.0)\n",
      "('ind_recibo_ult1_prev', 194.0)\n",
      "('ind_cco_fin_ult1_prev', 189.0)\n",
      "('indresi', 135.0)\n",
      "('ind_nom_pens_ult1_prev', 131.0)\n",
      "('renta_prev', 127.0)\n",
      "('fecha_alta_month_prev', 125.0)\n",
      "('nomprov_prev', 123.0)\n",
      "('fecha_alta_year_prev', 121.0)\n",
      "('canal_entrada_prev', 117.0)\n",
      "('ind_ecue_fin_ult1_prev', 78.0)\n",
      "('ind_nomina_ult1_prev', 77.0)\n",
      "('ind_empleado_prev', 60.0)\n",
      "('ind_tjcr_fin_ult1_prev', 44.0)\n",
      "('ind_ctma_fin_ult1_prev', 31.0)\n",
      "('indrel', 30.0)\n",
      "('ind_actividad_cliente_prev', 30.0)\n",
      "('ind_dela_fin_ult1_prev', 27.0)\n",
      "('ind_nuevo_prev', 24.0)\n",
      "('ind_ctop_fin_ult1_prev', 24.0)\n",
      "('pais_residencia_prev', 19.0)\n",
      "('sexo_prev', 19.0)\n",
      "('tiprel_1mes_prev', 18.0)\n",
      "('segmento_prev', 17.0)\n",
      "('ult_fec_cli_1t_month', 15.0)\n",
      "('ind_reca_fin_ult1_prev', 13.0)\n",
      "('ind_fond_fin_ult1_prev', 10.0)\n",
      "('indrel_1mes', 9.0)\n",
      "('ind_ctpp_fin_ult1_prev', 7.0)\n",
      "('indrel_1mes_prev', 4.0)\n",
      "('indext_prev', 3.0)\n",
      "('ult_fec_cli_1t_year', 2.0)\n",
      "('ind_valo_fin_ult1_prev', 2.0)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost モデルを全体の訓練データで学習します。\n",
    "X_all = XY[features].values\n",
    "Y_all = XY['y'].values\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
    "watch_list = [(dall, 'train')]\n",
    "# # ツリーの個数を増加したデータの量に比例して増やします。\n",
    "# best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "# XGBoost モデル再学習！\n",
    "# model = xgb.train(params, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
    "model = xgb.train(\n",
    "    params, \n",
    "    dall, \n",
    "    evals=watch_list,\n",
    "    # 最大で 1000 ラウンドまで学習する\n",
    "    num_boost_round=10,\n",
    "    # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "    early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "# 変数の重要度を出力してみます。予想していた変数が上位に来ていますか？\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)\n",
    "\n",
    "# Kaggleに提出するため、テストデータに対する予測値を求めます。\n",
    "X_tst = tst[features].values\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=model.best_ntree_limit)\n",
    "ncodpers_tst = tst['ncodpers'].values\n",
    "preds_tst = preds_tst - tst[[prod + '_prev' for prod in prods]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77fec6-9b49-4588-9a2e-7bbbbe071800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(C, Y_test)\n",
    "\n",
    "    \"\"\"\n",
    "    予測結果から提出用のcsvファイルを作成。\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    C : list\n",
    "        予測対象の顧客IDリスト(ncodpers)。\n",
    "        \n",
    "    Y_test : array\n",
    "        各商品の獲得予測値。\n",
    "    \n",
    "    \"\"\"\n",
    "    submit_file = pd.DataFrame()\n",
    "    C_list = []\n",
    "    test_preds = []\n",
    "    for ncodper, pred in zip(C, Y_test):\n",
    "        y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "        y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "        y_prods = [p for y,p,ip in y_prods]\n",
    "        C_list.append(ncodper)\n",
    "        test_preds.append(' '.join(y_prods))\n",
    "\n",
    "    submit_file['ncodpers'] = C_list\n",
    "    submit_file['added_products'] = test_preds\n",
    "    submit_file.to_csv('collab_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3791b8-2b90-41af-b32d-8ce723036704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 提出ファイルを生成します。\n",
    "# submit_file = open('xgb.baseline.2015-06-28', 'w')\n",
    "# submit_file.write('ncodpers,added_products\\n')\n",
    "# for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "#     y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "#     y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "#     y_prods = [p for y,p,ip in y_prods]\n",
    "#     submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
