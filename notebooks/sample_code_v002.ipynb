{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488701b1-2d56-42d9-a3e8-12d2701531e0",
   "metadata": {},
   "source": [
    "# scripts/convert_to_feather.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "487cc748-a835-4e5e-8dbb-bced2d8e186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293eadd2-45eb-4d22-91e5-e6cc8d7dfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\n",
    "    'train_ver2',\n",
    "    'test_ver2',\n",
    "]\n",
    "\n",
    "extension = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2f7c01-ee9c-459d-a4cd-7d3fed206f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== train_ver2 の作成開始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (5,8,11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== train_ver2 の作成完了\n",
      "=== test_ver2 の作成開始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== test_ver2 の作成完了\n"
     ]
    }
   ],
   "source": [
    "for t in target:\n",
    "    \n",
    "    print(f'=== {t} の作成開始')\n",
    "    \n",
    "    df = pd.read_csv('../data/input/' + t + '.' + extension, encoding=\"utf-8\")\n",
    "    \n",
    "    ## データクレンジングしてからfeather化 ##\n",
    "    # 不正な値があるカラム 'age', 'antiguedad', 'indrel_1mes', 'conyuemp'\n",
    "    \n",
    "    # 数値型変数の特異値と欠損値を -99に代替し、整数型に変換します。\n",
    "    df['age'].replace(' NA', -99, inplace=True)\n",
    "    df['age'] = df['age'].astype(np.int8)\n",
    "    df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "    df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "    df['renta'].replace('         NA', -99, inplace=True)\n",
    "    df['renta'].fillna(-99, inplace=True)\n",
    "    df['renta'] = df['renta'].astype(float).astype(np.int8\n",
    "    df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "    df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "    df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "    df['conyuemp'].fillna('N', inplace=True) # Nが多いのでNで穴埋め\n",
    "    \n",
    "    df.to_feather('../data/input/' + t + '.feather')\n",
    "    \n",
    "    print(f'=== {t} の作成完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8670a4d3-f5bc-4cf4-ada6-122b9be5f5e1",
   "metadata": {},
   "source": [
    "# features/create.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef3ff2b-22f1-4f0c-a5f1-11aaaa54d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import sys\n",
    "\n",
    "sys.path.append('../features/')\n",
    "from base import Feature, get_arguments, generate_features\n",
    "\n",
    "Feature.dir = 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6583aec-cced-4aa5-8dec-f9f6c42f4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日付を数字に変換する関数です。 2015-01-28は 1, 2016-06-28は 18に変換します。\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b717b1e-40e0-4a57-a4eb-70ac35b822b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 48)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'date_to_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8078/2647192517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# コード 2-12と類似したコードの流れです\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# 日付を数字に変換し int_dateに保存します。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'int_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fecha_dato'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# generate_features(globals(), args.force)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'date_to_int' is not defined"
     ]
    }
   ],
   "source": [
    "# args = get_arguments()\n",
    "\n",
    "'''\n",
    "    読み込み・準備\n",
    "\n",
    "'''\n",
    "\n",
    "train = pd.read_feather('../data/input/train_ver2.feather')\n",
    "\n",
    "test = pd.read_feather('../data/input/test_ver2.feather')\n",
    "\n",
    "# 製品の変数を別途に保存しておきます。\n",
    "prods = train.columns[24:].tolist()\n",
    "\n",
    "# 24個の製品を1つも保有していない顧客のデータを除去します。\n",
    "no_product = train[prods].sum(axis=1) == 0\n",
    "train= train[~no_product]\n",
    "## あとで消す\n",
    "# メモリに乗らないのでサンプリング\n",
    "train = train.sample(1000000)\n",
    "print(train.shape)\n",
    "\n",
    "# 製品変数の欠損値をあらかじめ0に代替しておきます。\n",
    "train[prods] = train[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# 訓練データとテストデータを統合します。テストデータにない製品変数は0で埋めます。\n",
    "for col in train.columns[24:]:\n",
    "    test[col] = 0\n",
    "\n",
    "'''\n",
    "    trainとtestをunionしてデータフレームを作成\n",
    "\n",
    "'''    \n",
    "    \n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "\n",
    "'''\n",
    "    データ加工\n",
    "\n",
    "'''\n",
    "\n",
    "# カテゴリ変数を .factorize() 関数に通して label encodingします。\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "\n",
    "# (特徴量エンジニアリング) 2つの日付変数から年度と月の情報を抽出します。\n",
    "df['fecha_alta'].fillna(0.0, inplace=True)\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "df = df.drop(['fecha_alta'], axis =1)\n",
    "\n",
    "df['ult_fec_cli_1t'].fillna(0.0, inplace=True)\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "df['ult_fec_cli_1t'] = df['ult_fec_cli_1t'].astype(object)\n",
    "df = df.drop(['ult_fec_cli_1t'], axis =1)\n",
    "\n",
    "# それ以外の変数の欠損値をすべて -99に代替します。\n",
    "df.fillna(-99, inplace=True)\n",
    "\n",
    "# (特徴量エンジニアリング) lag-1 データを生成します。\n",
    "# コード 2-12と類似したコードの流れです\n",
    "# 日付を数字に変換し int_dateに保存します。\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "# generate_features(globals(), args.force)\n",
    "\n",
    "'''\n",
    "    保存\n",
    "\n",
    "'''\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_feather('../data/input/' + 'df' + '.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a22756b-d4df-4c42-8409-83bcdcfb025e",
   "metadata": {},
   "source": [
    "# run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4309c50d-e168-40fc-beaa-f7071467a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import argparse\n",
    "import json\n",
    "import gc\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c9a208-90d6-4493-851f-2154d43f6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    # AP@7なので、最大7個まで使用します。\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # 点数を付与する条件は次のとおり :\n",
    "        # 予測値が正答に存在し (‘p in actual’)\n",
    "        # 予測値に重複がなければ (‘p not in predicted[:i]’) \n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    # 正答値が空白である場合、ともかく 0.0点を返します。\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    # 正答の個数(len(actual))として average precisionを求めます。\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    # list of listである正答値(actual)と予測値(predicted)から顧客別 Average Precisionを求め, np.mean()を通して平均を計算します。\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345e8f4a-333b-4e09-a8d9-602152e896a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', default='../configs/default.json')\n",
    "# options = parser.parse_args()\n",
    "options = parser.parse_args([])\n",
    "config = json.load(open(options.config))\n",
    "\n",
    "prods = config['target']\n",
    "features = config['features']\n",
    "params = config['model_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61c1e49-8173-444d-99e3-faecb4e9a1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather('../data/input/' + 'df' + '.feather')\n",
    "\n",
    "# データをコピーし, int_date 日付に1を加え lagを生成します。変数名に _prevを追加します。\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1\n",
    "\n",
    "# 原本データと lag データを ncodperと int_date を基準として合わせます。lag データの int_dateは 1 だけ押されているため、前の月の製品情報が挿入されます。\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# メモリの効率化のために、不必要な変数をメモリから除去します。\n",
    "del df, df_lag\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bec174-d968-4729-b8b0-610770a0999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前の月の製品情報が存在しない場合に備えて、0に代替します。\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "df_trn.fillna(-99, inplace=True)\n",
    "\n",
    "# lag-1 変数を追加します。\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba082f3-8586-4948-a398-e643a0e27d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Baseline モデル以後、多様な特徴量エンジニアリングをここに追加します。\n",
    "###\n",
    "\n",
    "## モデル学習\n",
    "# 学習のため、データを訓練、検証用に分離します。\n",
    "# 学習には 2016-01-28 ~ 2016-04-28 のデータだけを使用し、検証には 2016-05-28 のデータを使用します。\n",
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f87502-852c-4cd0-b6b4-87c0b6007186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データから新規購買件数だけを抽出します。\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "# 訓練、検証データに分離します。\n",
    "vld_date = '2016-05-28'\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c78751c-e8c7-4ee7-b48f-001cbb757f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lightgbm.callback import _format_eval_result\n",
    "\n",
    "\n",
    "def log_best(model, metric):\n",
    "    logging.debug(model.best_iteration)\n",
    "    logging.debug(model.best_score['valid_0'][metric])\n",
    "\n",
    "\n",
    "def log_evaluation(logger, period=1, show_stdv=True, level=logging.DEBUG):\n",
    "    def _callback(env):\n",
    "        if period > 0 and env.evaluation_result_list \\\n",
    "                and (env.iteration + 1) % period == 0:\n",
    "            result = '\\t'.join([\n",
    "                _format_eval_result(x, show_stdv)\n",
    "                for x in env.evaluation_result_list\n",
    "            ])\n",
    "            logger.log(level, '[{}]\\t{}'.format(env.iteration + 1, result))\n",
    "    _callback.order = 10\n",
    "    return _callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60756e4f-ecc2-4466-8ed5-cab1f5ab8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "# from logs.logger import log_evaluation\n",
    "\n",
    "\n",
    "def train_and_predict(X_train, X_valid, y_train, y_valid, X_test, params):\n",
    "\n",
    "    # データセットを生成する\n",
    "    xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "    xgb_eval  = xgb.DMatrix(X_valid, y_valid)\n",
    "    \n",
    "    watch_list = [(xgb_train, 'train'), (xgb_eval, 'eval')]\n",
    "\n",
    "    logging.debug(params)\n",
    "\n",
    "    # ロガーの作成\n",
    "    logger = logging.getLogger('main')\n",
    "    callbacks = [log_evaluation(logger, period=30)]\n",
    "\n",
    "    \n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = xgb.train(\n",
    "        params, xgb_train,\n",
    "        # モデルの評価用データを渡す\n",
    "        evals=watch_list,\n",
    "        # 最大で 1000 ラウンドまで学習する\n",
    "        num_boost_round=10,\n",
    "        # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "        early_stopping_rounds=20,\n",
    "        # ログ\n",
    "        # callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    xgb_test = xgb.DMatrix(X_test)\n",
    "    \n",
    "    # テストデータを予測する\n",
    "    y_pred = model.predict(xgb_test, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    # pickle.dump(model, open(\"xgb.baseline.pkl\", \"wb\"))\n",
    "    # best_ntree_limit = model.best_ntree_limit\n",
    "\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2f6b41-f45e-41bf-9561-518d3361b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練、検証データを XGBoost 形態に変換します。\n",
    "X_trtrain = XY_trn[features].values\n",
    "Y_trtrain = XY_trn['y'].values\n",
    "\n",
    "X_trvalid = XY_vld[features].values\n",
    "Y_trvalid = XY_vld['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095e7b1b-c8c1-4253-a74c-1c0993406697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "# MAP@7 評価基準のための準備作業です。\n",
    "# 顧客識別番号を抽出します。\n",
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld['ncodpers'].values\n",
    "# 検証データから新規購買を求めます。\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]    \n",
    "add_vld = vld[[prod + '_add' for prod in prods]].values\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
    "\n",
    "# 顧客別新規購買正答値を add_vld_listに保存し、総 countを count_vldに保存します。\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797c3c7a-7ac1-4b4b-8ed9-067ca1475edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:22:20] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:2.78372\teval-mlogloss:2.78954\n",
      "[1]\ttrain-mlogloss:2.60768\teval-mlogloss:2.61686\n",
      "[2]\ttrain-mlogloss:2.47880\teval-mlogloss:2.48968\n",
      "[3]\ttrain-mlogloss:2.37823\teval-mlogloss:2.39063\n",
      "[4]\ttrain-mlogloss:2.29472\teval-mlogloss:2.30823\n",
      "[5]\ttrain-mlogloss:2.22360\teval-mlogloss:2.23818\n",
      "[6]\ttrain-mlogloss:2.16244\teval-mlogloss:2.17824\n",
      "[7]\ttrain-mlogloss:2.10893\teval-mlogloss:2.12557\n",
      "[8]\ttrain-mlogloss:2.06174\teval-mlogloss:2.07920\n",
      "[9]\ttrain-mlogloss:2.02031\teval-mlogloss:2.03844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/xgboost/core.py:94: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  UserWarning\n"
     ]
    }
   ],
   "source": [
    "# 検証データに対する予測値を求めます。\n",
    "X_trtest = vld[features].values\n",
    "\n",
    "preds_vld, _ = train_and_predict(X_trtrain, X_trvalid, Y_trtrain, Y_trvalid, X_trtest, params)\n",
    "\n",
    "# 前の月に保有していた商品は新規購買が不可能なので、確率値からあらかじめ1を引いておきます。\n",
    "preds_vld = preds_vld - vld[[prod + '_prev' for prod in prods]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b40df506-de3e-48fc-af77-9fbc2472e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データの予測上位7個を抽出します。\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p,ip in y_prods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd1804c-c7b7-41cc-ba23-905a8b9b67d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データから得ることのできる MAP@7 の最高点 :  0.9149139731794046\n"
     ]
    }
   ],
   "source": [
    "# 検証データから得ることのできる MAP@7 の最高点をあらかじめ求めておきます。(0.042663)\n",
    "print('検証データから得ることのできる MAP@7 の最高点 : ', mapk(add_vld_list, add_vld_list, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30eca003-4afa-4a3f-b67e-d9d883fab337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "検証データの MAP@7の点数 :  0.7780943568355326\n"
     ]
    }
   ],
   "source": [
    "# 検証データの MAP@7の点数を求めます。(0.036466)\n",
    "print('検証データの MAP@7の点数 : ',mapk(add_vld_list, result_vld, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2d3498-c96b-43c4-ab13-427f9bc14123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:23:31] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mlogloss:2.78482\n",
      "[1]\ttrain-mlogloss:2.60897\n",
      "[2]\ttrain-mlogloss:2.48026\n",
      "[3]\ttrain-mlogloss:2.37990\n",
      "[4]\ttrain-mlogloss:2.29651\n",
      "[5]\ttrain-mlogloss:2.22555\n",
      "[6]\ttrain-mlogloss:2.16457\n",
      "[7]\ttrain-mlogloss:2.11114\n",
      "[8]\ttrain-mlogloss:2.06411\n",
      "[9]\ttrain-mlogloss:2.02269\n",
      "Feature importance:\n",
      "('antiguedad', 3580.0)\n",
      "('age', 3363.0)\n",
      "('renta', 2411.0)\n",
      "('nomprov', 1811.0)\n",
      "('fecha_alta_year', 1671.0)\n",
      "('canal_entrada', 1611.0)\n",
      "('fecha_alta_month', 1587.0)\n",
      "('segmento', 724.0)\n",
      "('sexo', 557.0)\n",
      "('tiprel_1mes', 424.0)\n",
      "('ind_actividad_cliente', 410.0)\n",
      "('indext', 249.0)\n",
      "('ind_nuevo', 108.0)\n",
      "('pais_residencia', 100.0)\n",
      "('indfall', 38.0)\n",
      "('indresi', 28.0)\n",
      "('ind_cco_fin_ult1_prev', 28.0)\n",
      "('ind_recibo_ult1_prev', 23.0)\n",
      "('age_prev', 21.0)\n",
      "('ind_cno_fin_ult1_prev', 18.0)\n",
      "('ind_empleado_prev', 15.0)\n",
      "('ind_empleado', 13.0)\n",
      "('antiguedad_prev', 11.0)\n",
      "('ind_nom_pens_ult1_prev', 11.0)\n",
      "('nomprov_prev', 10.0)\n",
      "('ind_actividad_cliente_prev', 7.0)\n",
      "('fecha_alta_year_prev', 7.0)\n",
      "('ind_tjcr_fin_ult1_prev', 7.0)\n",
      "('tiprel_1mes_prev', 5.0)\n",
      "('canal_entrada_prev', 5.0)\n",
      "('pais_residencia_prev', 4.0)\n",
      "('ind_nomina_ult1_prev', 4.0)\n",
      "('fecha_alta_month_prev', 3.0)\n",
      "('ind_ecue_fin_ult1_prev', 3.0)\n",
      "('sexo_prev', 2.0)\n",
      "('renta_prev', 2.0)\n",
      "('ind_nuevo_prev', 2.0)\n",
      "('ind_reca_fin_ult1_prev', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost モデルを全体の訓練データで学習します。\n",
    "X_all = XY[features].values\n",
    "Y_all = XY['y'].values\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
    "watch_list = [(dall, 'train')]\n",
    "# # ツリーの個数を増加したデータの量に比例して増やします。\n",
    "# best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "# XGBoost モデル再学習！\n",
    "# model = xgb.train(params, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
    "model = xgb.train(\n",
    "    params, \n",
    "    dall, \n",
    "    evals=watch_list,\n",
    "    # 最大で 1000 ラウンドまで学習する\n",
    "    num_boost_round=10,\n",
    "    # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "    early_stopping_rounds=20,\n",
    ")\n",
    "\n",
    "# 変数の重要度を出力してみます。予想していた変数が上位に来ていますか？\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)\n",
    "\n",
    "# Kaggleに提出するため、テストデータに対する予測値を求めます。\n",
    "X_tst = tst[features].values\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=model.best_ntree_limit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb77fec6-9b49-4588-9a2e-7bbbbe071800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(C, Y_test):\n",
    "\n",
    "    \"\"\"\n",
    "    予測結果から提出用のcsvファイルを作成。\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    C : list\n",
    "        予測対象の顧客IDリスト(ncodpers)。\n",
    "        \n",
    "    Y_test : array\n",
    "        各商品の獲得予測値。\n",
    "    \n",
    "    \"\"\"\n",
    "    submit_file = pd.DataFrame()\n",
    "    C_list = []\n",
    "    test_preds = []\n",
    "    for ncodper, pred in zip(C, Y_test):\n",
    "        y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "        y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "        y_prods = [p for y,p,ip in y_prods]\n",
    "        C_list.append(ncodper)\n",
    "        test_preds.append(' '.join(y_prods))\n",
    "\n",
    "    submit_file['ncodpers'] = C_list\n",
    "    submit_file['added_products'] = test_preds\n",
    "    submit_file.to_csv('collab_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a11bf0c-7c41-4715-b788-102b3d7d6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncodpers_tst = tst['ncodpers'].values\n",
    "preds_tst = preds_tst - tst[[prod + '_prev' for prod in prods]].values\n",
    "\n",
    "make_submission(ncodpers_tst, preds_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a02355-17d6-4e22-8a69-5b6caa770c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
