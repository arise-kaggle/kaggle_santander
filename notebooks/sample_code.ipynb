{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0044ac14-d420-4d1e-8691-30c1408fb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import polars as pl\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d308d1-d8b2-443c-8d1c-6be679a794ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (5,8,11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ubuntu/anaconda3/envs/py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# データを呼び出します。\n",
    "trn = pd.read_csv('../data/input/train_ver2.csv')\n",
    "tst = pd.read_csv('../data/input/test_ver2.csv')\n",
    "\n",
    "# trn = pl.read_csv('../data/input/train_ver2.csv', null_values=[' NA', 'NA','     NA', 'P'])\n",
    "# tst = pl.read_csv('../data/input/test_ver2.csv', null_values=[' NA', 'NA','     NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33360ab6-09bd-428e-9b35-59c619d48ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=7, default=0.0):\n",
    "    # AP@7なので、最大7個まで使用します。\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        # 点数を付与する条件は次のとおり :\n",
    "        # 予測値が正答に存在し (‘p in actual’)\n",
    "        # 予測値に重複がなければ (‘p not in predicted[:i]’) \n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    # 正答値が空白である場合、ともかく 0.0点を返します。\n",
    "    if not actual:\n",
    "        return default\n",
    "\n",
    "    # 正答の個数(len(actual))として average precisionを求めます。\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=7, default=0.0):\n",
    "    # list of listである正答値(actual)と予測値(predicted)から顧客別 Average Precisionを求め, np.mean()を通して平均を計算します。\n",
    "    return np.mean([apk(a, p, k, default) for a, p in zip(actual, predicted)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e37cdb-9ced-4c7c-811f-9b4cc2a5ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## データの前処理 ##\n",
    "\n",
    "# 製品の変数を別途に保存しておきます。\n",
    "prods = trn.columns[24:].tolist()\n",
    "\n",
    "# 製品変数の欠損値をあらかじめ0に代替しておきます。\n",
    "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
    "\n",
    "# 24個の製品を1つも保有していない顧客のデータを除去します。\n",
    "no_product = trn[prods].sum(axis=1) == 0\n",
    "trn = trn[~no_product]\n",
    "\n",
    "# 訓練データとテストデータを統合します。テストデータにない製品変数は0で埋めます。\n",
    "for col in trn.columns[24:]:\n",
    "    tst[col] = 0\n",
    "df = pd.concat([trn, tst], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6131879-1482-4850-bade-54bbe02b461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習に使用する変数を入れるlistです。\n",
    "features = []\n",
    "\n",
    "# カテゴリ変数を .factorize() 関数に通して label encodingします。\n",
    "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = df[col].factorize(na_sentinel=-99)\n",
    "features += categorical_cols\n",
    "\n",
    "# 数値型変数の特異値と欠損値を -99に代替し、整数型に変換します。\n",
    "df['age'].replace(' NA', -99, inplace=True)\n",
    "df['age'] = df['age'].astype(np.int8)\n",
    "\n",
    "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
    "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
    "\n",
    "df['renta'].replace('         NA', -99, inplace=True)\n",
    "df['renta'].fillna(-99, inplace=True)\n",
    "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
    "\n",
    "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
    "df['indrel_1mes'].fillna(-99, inplace=True)\n",
    "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
    "\n",
    "# 学習に使用する数値型変数を featuresに追加します。\n",
    "features += ['age','antiguedad','renta','ind_nuevo','indrel','indrel_1mes','ind_actividad_cliente']\n",
    "\n",
    "# (特徴量エンジニアリング) 2つの日付変数から年度と月の情報を抽出します。\n",
    "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['fecha_alta_month', 'fecha_alta_year']\n",
    "\n",
    "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
    "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
    "features += ['ult_fec_cli_1t_month', 'ult_fec_cli_1t_year']\n",
    "\n",
    "# それ以外の変数の欠損値をすべて -99に代替します。\n",
    "df.fillna(-99, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ccc7e-2d42-45dd-8863-1d2576a87f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (特徴量エンジニアリング) lag-1 データを生成します。\n",
    "# コード 2-12と類似したコードの流れです\n",
    "\n",
    "# 日付を数字に変換する関数です。 2015-01-28は 1, 2016-06-28は 18に変換します。\n",
    "def date_to_int(str_date):\n",
    "    Y, M, D = [int(a) for a in str_date.strip().split(\"-\")] \n",
    "    int_date = (int(Y) - 2015) * 12 + int(M)\n",
    "    return int_date\n",
    "\n",
    "# 日付を数字に変換し int_dateに保存します。\n",
    "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
    "\n",
    "# データをコピーし, int_date 日付に1を加え lagを生成します。変数名に _prevを追加します。\n",
    "df_lag = df.copy()\n",
    "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns ]\n",
    "df_lag['int_date'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a844a5-a38a-4933-ae0d-48e4a69c03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原本データと lag データを ncodperと int_date を基準として合わせます。lag データの int_dateは 1 だけ押されているため、前の月の製品情報が挿入されます。\n",
    "df_trn = df.merge(df_lag, on=['ncodpers','int_date'], how='left')\n",
    "\n",
    "# メモリの効率化のために、不必要な変数をメモリから除去します。\n",
    "del df, df_lag\n",
    "\n",
    "# 前の月の製品情報が存在しない場合に備えて、0に代替します。\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    df_trn[prev].fillna(0, inplace=True)\n",
    "df_trn.fillna(-99, inplace=True)\n",
    "\n",
    "# lag-1 変数を追加します。\n",
    "features += [feature + '_prev' for feature in features]\n",
    "features += [prod + '_prev' for prod in prods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bfd7d5-d5a4-4ab9-9bc6-311898f0c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Baseline モデル以後、多様な特徴量エンジニアリングをここに追加します。\n",
    "###\n",
    "\n",
    "\n",
    "## モデル学習\n",
    "# 学習のため、データを訓練、検証用に分離します。\n",
    "# 学習には 2016-01-28 ~ 2016-04-28 のデータだけを使用し、検証には 2016-05-28 のデータを使用します。\n",
    "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
    "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
    "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
    "del df_trn\n",
    "\n",
    "# 訓練データから新規購買件数だけを抽出します。\n",
    "X = []\n",
    "Y = []\n",
    "for i, prod in enumerate(prods):\n",
    "    prev = prod + '_prev'\n",
    "    prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
    "    prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
    "    X.append(prX)\n",
    "    Y.append(prY)\n",
    "XY = pd.concat(X)\n",
    "Y = np.hstack(Y)\n",
    "XY['y'] = Y\n",
    "\n",
    "# 訓練、検証データに分離します。\n",
    "vld_date = '2016-05-28'\n",
    "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
    "XY_vld = XY[XY['fecha_dato'] == vld_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efadad4-90ff-444e-b778-b83486421249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost モデルの parameterを設定します。\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 8,\n",
    "    'nthread': 4,\n",
    "    'num_class': len(prods),\n",
    "    'objective': 'multi:softprob',\n",
    "    'silent': 1,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'eta': 0.1,\n",
    "    'min_child_weight': 10,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'colsample_bylevel': 0.9,\n",
    "    'seed': 2018,\n",
    "    }\n",
    "\n",
    "# 訓練、検証データを XGBoost 形態に変換します。\n",
    "X_trn = XY_trn.as_matrix(columns=features)\n",
    "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
    "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
    "\n",
    "X_vld = XY_vld.as_matrix(columns=features)\n",
    "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "\n",
    "# XGBoost モデルを訓練データで学習させます！\n",
    "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
    "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)\n",
    "\n",
    "# 学習したモデルを保存します。\n",
    "import pickle\n",
    "pickle.dump(model, open(\"../model/xgb.baseline.pkl\", \"wb\"))\n",
    "best_ntree_limit = model.best_ntree_limit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d00ee5-bc50-4eb9-b438-cfc193671d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP@7 評価基準のための準備作業です。\n",
    "# 顧客識別番号を抽出します。\n",
    "vld = trn[trn['fecha_dato'] == vld_date]\n",
    "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
    "# 検証データから新規購買を求めます。\n",
    "for prod in prods:\n",
    "    prev = prod + '_prev'\n",
    "    padd = prod + '_add'\n",
    "    vld[padd] = vld[prod] - vld[prev]    \n",
    "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
    "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
    "\n",
    "# 顧客別新規購買正答値を add_vld_listに保存し、総 countを count_vldに保存します。\n",
    "count_vld = 0\n",
    "for ncodper in range(len(ncodpers_vld)):\n",
    "    for prod in range(len(prods)):\n",
    "        if add_vld[ncodper, prod] > 0:\n",
    "            add_vld_list[ncodper].append(prod)\n",
    "            count_vld += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de7c2a3-1ece-4fa0-9ea0-4c86259de37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list() for i in range(len(['a','b','c']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6a089-265c-41f4-afa1-b3721a070b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データから得ることのできる MAP@7 の最高点をあらかじめ求めておきます。(0.042663)\n",
    "print(mapk(add_vld_list, add_vld_list, 7, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3494d-89e4-466b-9303-c7651b5eea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証データに対する予測値を求めます。\n",
    "X_vld = vld.as_matrix(columns=features)\n",
    "Y_vld = vld.as_matrix(columns=['y'])\n",
    "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
    "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
    "\n",
    "# 前の月に保有していた商品は新規購買が不可能なので、確率値からあらかじめ1を引いておきます。\n",
    "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "# 検証データの予測上位7個を抽出します。\n",
    "result_vld = []\n",
    "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    result_vld.append([ip for y,p,ip in y_prods])\n",
    "    \n",
    "# 検証データの MAP@7の点数を求めます。(0.036466)\n",
    "print(mapk(add_vld_list, result_vld, 7, 0.0))\n",
    "\n",
    "# XGBoost モデルを全体の訓練データで学習します。\n",
    "X_all = XY.as_matrix(columns=features)\n",
    "Y_all = XY.as_matrix(columns=['y'])\n",
    "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
    "watch_list = [(dall, 'train')]\n",
    "# ツリーの個数を増加したデータの量に比例して増やします。\n",
    "best_ntree_limit = int(best_ntree_limit * (len(XY_trn) + len(XY_vld)) / len(XY_trn))\n",
    "# XGBoost モデル再学習！\n",
    "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
    "\n",
    "# 変数の重要度を出力してみます。予想していた変数が上位に来ていますか？\n",
    "print(\"Feature importance:\")\n",
    "for kv in sorted([(k,v) for k,v in model.get_fscore().items()], key=lambda kv: kv[1], reverse=True):\n",
    "    print(kv)\n",
    "\n",
    "# Kaggleに提出するため、テストデータに対する予測値を求めます。\n",
    "X_tst = tst.as_matrix(columns=features)\n",
    "dtst = xgb.DMatrix(X_tst, feature_names=features)\n",
    "preds_tst = model.predict(dtst, ntree_limit=best_ntree_limit)\n",
    "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
    "preds_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
    "\n",
    "# 提出ファイルを生成します。\n",
    "submit_file = open('../model/xgb.baseline.2015-06-28', 'w')\n",
    "submit_file.write('ncodpers,added_products\\n')\n",
    "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
    "    y_prods = [(y,p,ip) for y,p,ip in zip(pred, prods, range(len(prods)))]\n",
    "    y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
    "    y_prods = [p for y,p,ip in y_prods]\n",
    "    submit_file.write('{},{}\\n'.format(int(ncodper), ' '.join(y_prods)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
